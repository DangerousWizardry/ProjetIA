{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import collections\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/wb_dataset.txt', sep='\\t',header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mortalité par cancer en fonction des dépenses en santé du pays, des dépenses directes de chaque citoyen en santé, du PIB et de l'indice de capital humain (World Bank Indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute selection\n",
    "===================\n",
    "\n",
    "* Remove attributes containing many missing values.\n",
    "\n",
    "* Remove attributes that seem redundant because of strong correlations.\n",
    "\n",
    "* Used derived attributes to exhibit variables that could be more pertinent (relative value, ratio, difference, relative variation, indicator combining several attributes, ...).\n",
    "\n",
    "* Choose a subset of the dimensions to focus on some aspects and/or to simplify the interpretations. For methods that use distances, reduce the number of dimensions between 4 and 6, and standardize the data if necessary.\n",
    "\n",
    "Remark: It is possible to complete the dataset with other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming attribute for easier use\n",
    "# Time = removed\n",
    "# Time Code = removed\n",
    "# Country Name = country_name\n",
    "# Country Code = country_code\n",
    "# Mortality from CVD, cancer, diabetes or CRD between exact ages 30 and 70 (%) = mortality\n",
    "# Current health expenditure (% of GDP) [SH.XPD.CHEX.GD.ZS] = health_cost_percent\n",
    "# Current health expenditure per capita (current US$) [SH.XPD.CHEX.PC.CD] = health_cost_capita_percent\n",
    "# Out-of-pocket expenditure (% of current health expenditure) [SH.XPD.OOPC.CH.ZS] = health_oop_cost\n",
    "# GDP (current US$) [NY.GDP.MKTP.CD] = gdp\n",
    "# GDP per capita (current US$) [NY.GDP.PCAP.CD] = gdp_capita\n",
    "# Human capital index (HCI) (scale 0-1) [HD.HCI.OVRL] hci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the 2 first column (time and time code)\n",
    "data.drop([\"Time\",\"Time Code\"], axis=1, inplace=True)\n",
    "# Remove the last 5 lines that are now empty\n",
    "data.drop(data.tail(5).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['country_name','country_code','mortality','health_cost_percent','health_cost_capita_percent','health_oop_cost','gdp','gdp_capita','hci']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp=pd.to_numeric(data[data[\"health_cost_percent\"]!=\"..\"][\"health_cost_percent\"],downcast='float')\n",
    "hccp=pd.to_numeric(data[data[\"health_cost_capita_percent\"]!=\"..\"][\"health_cost_capita_percent\"],downcast='float')\n",
    "np.corrcoef(hcp,hccp)\n",
    "#the correlation between health_cost_percent and health_cost_capita_percent does not seem to be significant enough to remove one of these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = pd.to_numeric(data[data[\"gdp\"]!=\"..\"][\"gdp\"],downcast='float')\n",
    "gdpc = pd.to_numeric(data[data[\"gdp_capita\"]!=\"..\"][\"gdp_capita\"],downcast='float')\n",
    "np.corrcoef(gdp,gdpc)\n",
    "#As well, the correlation between gdp and gdp_capita does not seem to be significant enough to remove one of these two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object selection\n",
    "================\n",
    "\n",
    "* Remove objects containing missing values (except if using methods that handle clearly the missing values).\n",
    "\n",
    "* Identified the outliers (exceptional objects, noise, ...) in 1D, 2D, n-dimensions. Keep track of them and eventually remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the region object because they are already agregate of data which we are not interested into\n",
    "count_removed_region = len(data) - data.index[data['country_code'] == \"ZWE\"][0] - 1\n",
    "if count_removed_region > 0 :\n",
    "    data.drop(data.tail(count_removed_region).index,inplace=True)\n",
    "    \n",
    "print(count_removed_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove objects for which we do not have data about cancers mortality\n",
    "count_removed_nodata = len(data.loc[data['mortality'] == \"..\"])\n",
    "if (count_removed_nodata > 0):\n",
    "    data.drop(data.index[data['mortality'] == \"..\"],inplace=True)\n",
    "\n",
    "print(count_removed_nodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We choose to remove the objects for which at least one of the selected attributes is missing\n",
    "missing_attributes = pd.DataFrame(data.apply(pd.Series.value_counts, axis=1)[\"..\"])\n",
    "missing_attributes_index = missing_attributes.index[missing_attributes[\"..\"] > 0]\n",
    "if (len(missing_attributes_index)>0):\n",
    "    data.drop(missing_attributes_index,inplace=True)\n",
    "print(len(missing_attributes_index))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_numeric(data[data[\"mortality\"] != \"..\"][nomColonne], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['mortality','health_cost_percent','health_cost_capita_percent','health_oop_cost','gdp','gdp_capita','hci']] = data[['mortality','health_cost_percent','health_cost_capita_percent','health_oop_cost','gdp','gdp_capita','hci']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_clean_dataset = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at outliers\n",
    "classes=pd.cut(data[\"mortality\"],5, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\"])\n",
    "full_clean_dataset[\"mortality_class\"] = classes\n",
    "outliers_index = full_clean_dataset.index[full_clean_dataset[\"mortality_class\"]==\"very_high\"]\n",
    "data.drop(outliers_index,inplace=True)\n",
    "outliers_index = full_clean_dataset.index[full_clean_dataset[\"mortality_class\"]==\"high\"]\n",
    "data.drop(outliers_index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Clustering\n",
    "==========\n",
    "\n",
    "* Look for clusters of globular shapes and of arbitrary shapes, using in particular K-means, hierarchical complete/single and DBSCAN.\n",
    "\n",
    "* Compute dendrograms for hierarchical clustering.\n",
    "\n",
    "* Determine good candidates for the number of clusters (using SSE, silhouette coefficient and grouping distance curves).\n",
    "\n",
    "* Study the stability of the K-means convergence.\n",
    "\n",
    "* Compare (using entropy or mutual entropy, and contingency tables) the content of the clusters to a known labelling or to the result of another clustering.\n",
    "\n",
    "* Describe the envelope (the borders) of the clusters using a decision tree (on a dataset having at least 4 dimensions).\n",
    "\n",
    "\n",
    "Remarks:\n",
    "\n",
    "- Removing outliers can improve the stability and the dispersion.\n",
    "\n",
    "- Clustering evaluation can be made by comparing SSE and silhouette coefficient obtain of the data to their values on random dataset or on partially randomize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierachical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define X and Y for Hierachical Clustering\n",
    "#Y=pd.cut(full_clean_dataset[\"mortality\"],5, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\"])\n",
    "X=full_clean_dataset[['health_cost_percent','health_cost_capita_percent','health_oop_cost','gdp','gdp_capita','hci']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(X, method='complete', metric='euclidean',optimal_ordering=True)\n",
    "#Draw the dendrogram:\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "dendro = sch.dendrogram(Z, orientation='left', leaf_rotation=0, leaf_font_size=15,labels=list(full_clean_dataset['country_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(Z[:,2],'o-')\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used complete hierachical clustering. By looking at the grouping distance curve, it seems that 6 groups can be highlighted. We will test this method with 6 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects=full_clean_dataset[['health_cost_percent','health_cost_capita_percent','health_oop_cost','gdp','gdp_capita','hci']]\n",
    "#We must scale and center data in order to use dbscan efficiently\n",
    "objects = (objects - objects.mean()) / (objects.max() - objects.min())\n",
    "unclassified = []\n",
    "nb_cluster = []\n",
    "for i in range(0,100):\n",
    "    dbscan = DBSCAN(eps=(0.10 + (i*0.001)), min_samples=2)\n",
    "    dbscan.fit(objects)\n",
    "    unclassified.append(np.count_nonzero(dbscan.labels_ == -1))\n",
    "    nb_cluster.append(max(dbscan.labels_))\n",
    "plt.plot(list(range(0,100)),unclassified)\n",
    "plt.plot(list(range(0,100)),nb_cluster)\n",
    "plt.axhline(y = len(objects)*0.2, color = 'r', linestyle = '-',label=\"20% of value is unclassified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want at least 80% of our values to be classified, we must choose eps ~>0.136. We choose eps = 0.145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.145, min_samples=2)\n",
    "dbscan.fit(objects)\n",
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster = dbscan.labels_\n",
    "objects['cluster']= cluster\n",
    "no_noise_objects = objects[objects['cluster']!=-1]\n",
    "sns.pairplot(data=no_noise_objects,hue='cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBScan seems to have difficulties in differentiating clusters. There seems to be a lot of noise in his prediction. This may be caused by scaling and centering of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get SSE when varying the number of clusters\n",
    "objects=full_clean_dataset[['health_cost_percent','health_cost_capita_percent','health_oop_cost','gdp','gdp_capita','hci']]\n",
    "sse_list = []\n",
    "for i in range(2,11):\n",
    "    km_i_clusters=KMeans(n_clusters=i)\n",
    "    km_i_clusters.fit(objects)\n",
    "    sse_list = sse_list + [km_i_clusters.inertia_]\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.plot(list(range(2,11)),sse_list,'bo--')\n",
    "plt.grid()\n",
    "plt.xlabel(\"nb of clusters\",fontsize=14)\n",
    "plt.ylabel(\"SSE\",fontsize=14)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing SSE values, 4 or 5 clusters seem to be good choices. We decide to choose 5 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know if our data are noisy or if the clusters are easily drawn, we study the stability of the K-means convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stability(km,df,iterations=100):\n",
    "    avg_silhouette_coef = []\n",
    "    sse_list = []\n",
    "    for i in range(100):\n",
    "        km.fit(df)\n",
    "        labels = km.predict(df)\n",
    "        avg_silhouette_coef.append(silhouette_score(df, labels,metric='euclidean'))\n",
    "    avg_silhouette_coef = np.asarray(avg_silhouette_coef)\n",
    "    return(avg_silhouette_coef.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5,init='random',n_init=1,random_state=1) # create a KMeans object\n",
    "compute_stability(km,objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance is very low, whatever the initial point chosen by Kmeans, the convergence clusters seem to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km=KMeans(n_clusters=5)\n",
    "result=km.fit(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Hierachical Clustering Score - 6 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sch.fcluster(Z, 6, criterion='maxclust')\n",
    "classes=pd.cut(full_clean_dataset[\"mortality\"],6, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\",\"very_very_high\"])\n",
    "crosstab=pd.crosstab(clusters,classes)\n",
    "sns.heatmap(crosstab, annot=True)\n",
    "accuracy = np.diag(crosstab).sum() / crosstab.to_numpy().sum()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) DBScan - 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dbscan.labels_\n",
    "objects['cluster']= cluster\n",
    "objects['classes']= pd.cut(full_clean_dataset[\"mortality\"],5, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\"])\n",
    "\n",
    "no_noise_objects = objects[objects['cluster']!=-1]\n",
    "\n",
    "crosstab=pd.crosstab(no_noise_objects['cluster'],no_noise_objects['classes'])\n",
    "sns.heatmap(crosstab, annot=True)\n",
    "accuracy = (62 + 12 + 2) / crosstab.to_numpy().sum()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Kmeans - 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=result.labels_\n",
    "classes=pd.cut(full_clean_dataset[\"mortality\"],5, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\"])\n",
    "crosstab=pd.crosstab(clusters,classes)\n",
    "sns.heatmap(crosstab, annot=True)\n",
    "accuracy = (69 + 8) / crosstab.to_numpy().sum()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = full_clean_dataset.copy()\n",
    "objects['cluster']= clusters\n",
    "sns.pairplot(data=objects,hue='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects[objects['cluster']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't find any real relation between the different countries by using Clustering on our dataset.\n",
    "\n",
    "We can only spot 3 tendencies\n",
    "\n",
    "* A first group of countries that look globally similar. It contains Australia, France, Italy, Korea, Canada for instance. (cluster 2)\n",
    "\n",
    "* A second group of countries which contains only Germany and Japan that seem to be really cost-efficient in decreasing mortality\n",
    "\n",
    "* Two specific countries considered as alone in their cluster because of their specificity : China and USA \n",
    "    * China has a very high GPD but an average health system\n",
    "    * USA has a very expensive health system but not cost efficient at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification\n",
    "==============\n",
    "\n",
    "The goal of this section is to train Machine Learning classifiers to predict the cancer mortality of a given country from its other attributes\n",
    "\n",
    "* Construct a label by discretisation of an attribute (this label can be built by clustering the values of this attribute). Use this label as class label.\n",
    "\n",
    "* Compare the results obtained using decision trees and the K nearest neighbors.\n",
    "\n",
    "* Evaluate the quality of the model using cross validation. Report the score for each subset and the global score.\n",
    "\n",
    "* Modify the learning parameters to detect of possible overfitting.\n",
    "\n",
    "\n",
    "Remarks:\n",
    "\n",
    "- A contingency table can be use to analyse the errors by class.\n",
    "\n",
    "- Removing outliers can reduce error.\n",
    "\n",
    "- A classification model can be use to predict labels of a targeted attribute for objects where this attribute value is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have already clustered the values of \"mortality\" in the Clustering section. We can use this label.\n",
    "+ Now, we split the dataset into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes=pd.cut(full_clean_dataset[\"mortality\"],5, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\"])\n",
    "X=full_clean_dataset.copy()\n",
    "y=pd.cut(full_clean_dataset[\"mortality\"],5, labels=[\"low\",\"medium\", \"average\", \"high\",\"very_high\"])\n",
    "print(collections.Counter(y))\n",
    "del X['country_name']\n",
    "del X['country_code']\n",
    "del X['mortality_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0) #try with test_size=0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the distribution of the data has some lack for high and very_high classified data.\n",
    "He can cause some problem of prediction accuracy for high classes\n",
    "\n",
    "+ Then, we create a Decision Tree instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We fit the Decision Tree using the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We use the DecisionTree to predict the class membership of the test set instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We can now compute the confusion matrix and model's accuracy by comparing y_test and the prediction we have just made y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "sns.heatmap(pd.crosstab(y_test,y_predict), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model seems to have a very good accuracy in predicting the mortality class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attributes may have to be scaled to prevent distance measures from being dominated by one of the attributes\n",
    "#But I think it's ok since we've already done that for clustering section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "zscore = StandardScaler().fit(X)\n",
    "X_z = pd.DataFrame(zscore.transform(X), index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "knn = KNeighborsClassifier()\n",
    "scores = cross_validate(knn, X, y, return_train_score=True)\n",
    "scores = pd.DataFrame(scores).mean()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "scores_z = cross_validate(knn, X_z, y, return_train_score=True)\n",
    "scores_z = pd.DataFrame(scores_z).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scores = pd.DataFrame({\"Raw\": scores, \"Zscore\":scores_z})\n",
    "sns.heatmap(full_scores,annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = [1,3,5]\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "distances = [\"euclidean\",\"manhattan\"]\n",
    "\n",
    "scoring = ['accuracy','precision_weighted','recall_weighted','f1_weighted']\n",
    "\n",
    "full_scores = {}\n",
    "for k in n_neighbors:\n",
    "    for d in distances:\n",
    "        for w in weights:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, weights=w, metric=d)\n",
    "            scores = cross_validate(knn, X_z, y, scoring=scoring, return_train_score=True)\n",
    "            scores = pd.DataFrame(scores).mean()\n",
    "            full_scores[str(k)+\"-\"+d+\"-\"+w] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning caused by the lack of data in some classes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scores = pd.DataFrame(full_scores)\n",
    "sns.heatmap(full_scores.T.round(2),annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the predictions obtained with the Decision Tree method are more accurate than the ones obtained by using K nearest neighbors method. In fact, the accuracy of our results obtained by Decision Tree method are 96% accurate, whereas the ones obtained by K nearest neighbors are around 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We want to evaluate the quality of our model using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold #cross-validation splitter\n",
    "from sklearn.model_selection import cross_validate #cross-validation evaluation of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we create a stratified cross-validation splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_ = ['accuracy','precision_macro','precision_weighted','recall_macro','recall_weighted','f1_macro','f1_weighted']\n",
    "scores = cross_validate(dt, X, y, scoring=scoring_,cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Global accuracy over all folds: %0.6f (+/- %0.6f)'\n",
    "      % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))\n",
    "print('For each metric, list the score values on each fold:')\n",
    "full_scores = pd.DataFrame(scores)\n",
    "sns.heatmap(full_scores.T.round(3),annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global score and the score of each subset allow us to validate our model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another method\n",
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(criterion = 'entropy', random_state=10, min_samples_leaf=3)\n",
    "scores = cross_validate(model, X, classes, scoring=scoring_,cv=cv, return_train_score=False)\n",
    "print('Global accuracy over all folds: %0.6f (+/- %0.6f)'\n",
    "      % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))\n",
    "full_scores = pd.DataFrame(scores)\n",
    "sns.heatmap(full_scores.T.round(3),annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test several maximum numbers of leaves\n",
    "cv = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "results = {}\n",
    "for leaves in range(2,20):\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=leaves,criterion=\"entropy\")\n",
    "    \n",
    "    local_results = cross_validate(dt, X, y, scoring=[\"accuracy\"],cv=cv, return_train_score=True)\n",
    "    avg_local_results = pd.DataFrame(local_results).mean()\n",
    "    results[leaves] = avg_local_results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results_df.T.index , results_df.T[\"test_accuracy\"],\"o--\")\n",
    "plt.plot(results_df.T.index , results_df.T[\"train_accuracy\"],\"o--\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Max Nb. Leaves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy doesn't increase if we add more leaves. There does not appear to be any overfitting.\n",
    "    Moreover, if we take 5 as the maximum number of leaves, we see that the accuracy will be the same as if we had taken 6 or more leaves. Then, we can take 5 leaves in order to avoid a too complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### 1) Materials and method\n",
    "* __Used clustering techniques__\n",
    "\n",
    "K-means, hierarchical complete/single and DBSCAN.\n",
    "\n",
    "* __Used classification techniques__\n",
    "\n",
    "Decision Tree and K-nearest Neighbors\n",
    "\n",
    "* __Used evaluating methods for clustering__\n",
    "\n",
    "SSE score, silhouette coefficient and grouping distance curves\n",
    "\n",
    "* __Used evaluating methods for classification__\n",
    "\n",
    "Cross validation and overfitting lookup\n",
    "\n",
    "#### 2) Results\n",
    "\n",
    "* We have tested 3 different methods of clustering on our data.\n",
    "\n",
    "First, we have used hierarchical clustering, with a complete method and using the euclidean distance and we have found 6 clusters thanks to the grouping distance curve.\n",
    "With this method, we found an accuracy of 34%.\n",
    "\n",
    "Then, we have used DBscan clustering. By fixing min_samples=2 as the minimum number of points in a cluster and epsilon=0.136 as the maximum distance between 2 points in a cluster, we found 5 clusters.\n",
    "The accuracy of this method is 58%.\n",
    "\n",
    "The last clustering method we have used is the K-means one. By comparing SSE values for different numbers of clusters, we decided to choose 5 clusters for this method.\n",
    "For this method, we found an accuracy of 49%.\n",
    "\n",
    "* We have then tested 2 methods of classification.\n",
    "\n",
    "The first one is the Decision Tree method. We found an accuracy of 96% with our model, which allows us to validate this model.\n",
    "\n",
    "The second one is the K-nearest neighbors method, for which we had an accuracy around 80 or 85% depending on the parameters we used.\n",
    "\n",
    "By using the cross validation, we found that the global accuracy of our Decision Tree method was 98.7%, which is a very good accuracy.\n",
    "We also tried to detect any overfitting, and came to the conclusion that it would be better to take 5 leaves, to have both sufficient accuracy and the simpliest possible model.\n",
    "\n",
    "\n",
    "#### 3) Discussion\n",
    "\n",
    "Thanks to clustering, we couldn't conclude about the difference in cancer mortality among countries. In fact, we didn't find any relevant attribute that influences mortality.\n",
    "However, using the Decision Tree method, we can predict the mortality class of a new country thanks to given data in other countries. The prediction we make with this method is very accurate so it can be usefull."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report content and format\n",
    "=========================\n",
    "\n",
    "* Keep track of the choices made and justify them.\n",
    "\n",
    "* Give commands and parameters so that the results can be reproduced.\n",
    "\n",
    "* Show in tables some views of subsets of the data, but not the complete view of all objects in the data. Give the attributes and their units, as well as the number of objects used.\n",
    "\n",
    "* Give results (values, graphics,...).\n",
    "\n",
    "* Try to interpret the results in the domain.\n",
    "\n",
    "\n",
    "Remarks:\n",
    "\n",
    "- It is possible to study several subsets of attributes (e.g., one for the clustering part, another for the classification tasks).\n",
    "\n",
    "- The report can suggest directions for future works, e.g., directions that have not been explored due to time constraints.\n",
    "\n",
    "- The document can be split in two reports: one for the clustering and one for the classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to edit the report\n",
    "======================\n",
    "\n",
    "A way to prepare the report is to add \"Markdows\" cells in the Jupyter notebook to insert text, and use #, ##, ###, #### for headings (section, subsection, subsubsection, paragraph). Next, to get a latex version of the notebook use: \"File -> Download as -> LaTeX\" (this requires Pandoc to be installed https://pandoc.org/installing.html). And then edit the .tex if needed (to add a title page, to clean some parts, ...), before compiling it.\n",
    "\n",
    "IMPORTANT 1: the end of long lines in cells containing python commands can be suppressed (due to the latex verbatim mode), to avoid this use lines of at most 80 characters and use \"\\\" to continue the command on the next line.\n",
    "\n",
    "IMPORTANT 2: if using \"File -> print preview\" to generate a pdf of the notebook, then the sections will not be numbered, and check also that there is no missing part in long lines.\n",
    "\n",
    "IMPORTANT 3: \"File -> Download as -> LaTeX\" may not work for the graphical representation of decision trees, depending on the version of sklearn and on external installed softwares. A workaround is to generate the pdf of the tree and then to include the pdf by a latex command.\n",
    "Example, with a cell containing the code:\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph # to display the tree\n",
    "\n",
    "replace the cell content by:\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"out_iris_decision_tree\") # to generate a pdf file\n",
    "\n",
    "then just below this cell add a Markdown cell containing the following tree lines:\n",
    "\\begin{center}\n",
    "\\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{out_iris_decision_tree.pdf}\n",
    "\\end{center}\n",
    "\n",
    "then generate the latex file with \"File -> Download as -> LaTeX\", put the file out_iris_decision_tree.pdf in the folder of the latex file, and compile the latex file.\n",
    "\n",
    "---\n",
    "\n",
    "Zip file to be send by mail\n",
    "===========================\n",
    "(mail to Christophe.Rigotti@insa-lyon.fr and Sergio.Peignier@insa-lyon.fr)\n",
    "\n",
    "Prepare a single folder with name the names of the authors (in lexicographic order): NAME1_NAME2. Zip this folder and send the file NAME1_NAME2.zip\n",
    "\n",
    "The folder must contains:\n",
    "\n",
    "- zip file(s) of the data file(s), (txt format to reproduce the work). \n",
    "\n",
    "- file(s), (txt format or pdf) containing the definitions of the variables given by the data provider.\n",
    "\n",
    "- the Jupyter notebook(s) (format .ipynb to reproduce the work).\n",
    "\n",
    "- the report in one or two pdf files.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
